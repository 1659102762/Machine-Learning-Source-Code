{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a876e358-2045-42fc-89c5-84258ff36ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 1. 0. 2. 1. 0. 0. 1. 2. 0. 1. 2. 2. 2. 0. 0. 1. 0. 0. 2. 0. 2.\n",
      " 0. 0. 0. 2. 2. 0. 2. 2. 0. 0. 1. 1. 2. 0. 0. 1. 1. 0. 2. 2. 2.]\n",
      "[0.97777778]\n",
      "  catagory  precision  recall  f1-score  support\n",
      "         0   1.000000     1.0  1.000000       18\n",
      "         1   1.000000     0.9  0.947368       10\n",
      "         2   0.965517     1.0  0.982456       17                                                 \n",
      "      accuracy                      0.977778  45\n",
      "     macro avg  0.988506  0.966667  0.976608  45\n",
      "  weighted avg  0.986973  0.977778  0.981676  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wyy\\AppData\\Local\\Temp\\ipykernel_7192\\2384810890.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  data[i,n_features+1]=unique[counts==np.max(counts)]\n"
     ]
    }
   ],
   "source": [
    "#KNN source code\n",
    "class KNN:\n",
    "    n_neighbors=None\n",
    "    weights=None\n",
    "    metric=None\n",
    "    def __init__(self,n_neighbors,weights='uniform',metric_p=2):\n",
    "        self.n_neighbors= n_neighbors\n",
    "        self.weights=weights\n",
    "        self.metric_p=metric_p\n",
    "#KNN.fit\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.x_train=x_train\n",
    "        self.y_train=y_train\n",
    "#KNN.predict\n",
    "    def predict(self,x_test,y_test):\n",
    "        import pandas as pd \n",
    "        import numpy as np\n",
    "        n_features=len(self.x_train[0])\n",
    "        train_size=len(self.x_train)\n",
    "        test_size=len(x_test)\n",
    "        catagories=np.unique(self.y_train)\n",
    "        n_catagories=len(catagories)\n",
    "#Build an empty matrix to contain all the calculated data\n",
    "        data=np.full((test_size,n_features+2+train_size),np.nan)\n",
    "#Fill the empty matrix with x_test and y_test\n",
    "        data[:,:n_features]=x_test\n",
    "        data[:,n_features]=y_test\n",
    "# Calculate the distance between test_points and train_points and fill the empty matrix with them\n",
    "        for i in range(test_size):\n",
    "            for j in range(train_size):\n",
    "                data[i,j+n_features+2]=(np.sum((np.abs(self.x_train[j]-x_test[i]))**self.metric_p))**(1/self.metric_p)\n",
    "# Sort the distance vectors and find out the disatnces and catagories of the closet n_neighbors train points\n",
    "            distance_catagory_top=np.concatenate((data[i,n_features+2:][:,np.newaxis],self.y_train[:,np.newaxis]),axis=1)\n",
    "            distance_catagory_top=distance_catagory_top[distance_catagory_top[:,0].argsort()][:self.n_neighbors]\n",
    "# Find out the predictions of test points through distance_catagory_top\n",
    "            unique,counts=np.unique(distance_catagory_top[:,-1],return_counts=True)\n",
    "            if self.weights=='uniform':\n",
    "                data[i,n_features+1]=unique[counts==np.max(counts)]\n",
    "            elif self.weights=='distance':\n",
    "                distance_weight=1/distance_catagory_top[:,0]\n",
    "                sum_distance_weight=np.zeros(len(unique))\n",
    "                for k in range(len(unique)):\n",
    "                    sum_distance_weight[k]=np.sum(distance_weight[distance_catagory_top[:,-1]==unqiue[k]])\n",
    "                data[i,n_features+1]=unique[sum_distance_weight==np.max(sum_distance_weight)]\n",
    "            else:\n",
    "                print(\"Error: input of 'weights' argument is wrong, it should either 'uniform' or 'distance'.\")      \n",
    "#Define attribuions and output the prediction results\n",
    "        self.data=data\n",
    "        self.y_pred=data[:,[n_features,n_features+1]]\n",
    "        self.pred=data[:,n_features+1]\n",
    "        print(data[:,n_features+1])     \n",
    "#KNN.score\n",
    "    def score(self,x_test,y_test):\n",
    "        import pandas as pd \n",
    "        import numpy as np\n",
    "        n_features=len(self.x_train[0])\n",
    "        judge=y_test==self.pred\n",
    "        unique,counts=np.unique(judge,return_counts=True)\n",
    "#Avoid the situation that counts[unique==False] or counts[unique==True] becomes empty when true or false not in judge causing empty score.\n",
    "        if True not in judge:\n",
    "            score=0.0\n",
    "        elif False not in judge:\n",
    "            score=1.0\n",
    "        else:\n",
    "            score=counts[unique==True]/(counts[unique==False]+counts[unique==True])\n",
    "        return print(score)\n",
    "#KNN.classfication_report\n",
    "#Calulate the confusion matrics\n",
    "    def classification_report(self,x_test,y_test):\n",
    "        import pandas as pd \n",
    "        import numpy as np\n",
    "        unique,counts=np.unique(y_test,return_counts=True)\n",
    "        n_features=len(self.x_train[0])\n",
    "        n_catagories=len(unique)\n",
    "        confusion_matrix=np.full((n_catagories,2,2),np.nan)\n",
    "        tp=np.full(n_catagories,np.nan)\n",
    "        fp=np.full(n_catagories,np.nan)\n",
    "        fn=np.full(n_catagories,np.nan)\n",
    "        tn=np.full(n_catagories,np.nan)\n",
    "        for i in range(n_catagories):\n",
    "            tp[i]=len(self.y_pred[(y_test==unique[i]) & (self.pred==unique[i])])/len(y_test[y_test==unique[i]])\n",
    "            fp[i]=len(self.y_pred[(y_test!=unique[i]) & (self.pred==unique[i])])/len(y_test[y_test!=unique[i]])\n",
    "            fn[i]=len(self.y_pred[(y_test==unique[i]) & (self.pred!=unique[i])])/len(y_test[y_test==unique[i]])\n",
    "            tn[i]=len(self.y_pred[(y_test!=unique[i]) & (self.pred!=unique[i])])/len(y_test[y_test!=unique[i]])\n",
    "            confusion_matrix[i]=np.array([tp[i],fp[i],fn[i],tn[i]]).reshape(2,2)\n",
    "        precision=tp/(tp+fp)\n",
    "        recall=tp/(tp+fn)\n",
    "        F_value=2*precision*recall/(precision+recall)\n",
    "        judge_b=y_test==self.pred\n",
    "        unique_d,counts_d=np.unique(judge_b,return_counts=True)\n",
    "        if True not in judge_b:\n",
    "            accuracy=0.0\n",
    "        elif False not in judge_b:\n",
    "            accuracy=1.0\n",
    "        else:\n",
    "            accuracy=counts_d[unique_d==True]/(counts_d[unique_d==False]+counts_d[unique_d==True])\n",
    "# Make the dataframe of classifcation report\n",
    "        support=counts\n",
    "        weight=support/np.sum(counts)\n",
    "        catagories=unique\n",
    "        macro_avg=np.array([np.average(precision),np.average(recall),np.average(F_value)]) \n",
    "        weighted_avg=np.array([np.sum(weight*precision),np.sum(weight*recall),np.sum(weight*F_value)])\n",
    "        df_report_a=pd.DataFrame({'catagory':catagories,'precision':precision,'recall':recall,'f1-score':F_value,'support':support})\n",
    "        df_report_b=pd.DataFrame([['accuracy','','',np.round(accuracy,6)[0],np.sum(counts)],['macro avg',macro_avg[0],macro_avg[1],macro_avg[2],np.sum(counts)]\n",
    "                    ,['weighted avg',weighted_avg[0],weighted_avg[1],weighted_avg[2],np.sum(counts)]])\n",
    "        df_report_a.index=[' ',' ',' ']\n",
    "        df_report_b.columns=[' ',' ',' ',' ',' ']\n",
    "        df_report_b.index=[' ',' ',' ']\n",
    "        self.confusion_matrix=confusion_matrix\n",
    "        return print(df_report_a,df_report_b)\n",
    "\n",
    "#test\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=load_iris().data\n",
    "y=load_iris().target\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=123)\n",
    "clf=KNN(5)\n",
    "clf.fit(x_train,y_train)\n",
    "clf.predict(x_test,y_test)\n",
    "clf.score(x_test,y_test)\n",
    "clf.classification_report(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a247e5c-66bb-4dd8-8dbf-7718b278e90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
