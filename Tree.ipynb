{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bd33e98-aef3-493f-b16a-59b124fad9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wyy\\AppData\\Local\\Temp\\ipykernel_3804\\712809077.py:142: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return str(int(np.unique(y)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'age': {0: {'student': {0: '0', 1: '1'}},\n",
       "   1: '1',\n",
       "   2: {'credit': {0: '1', 1: '0'}}}},\n",
       " array([0., 0., 1., 1., 1., 0.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Tree:\n",
    "    def fit(self,x_train,y_train,feature_names):\n",
    "        '''\n",
    "        x_train should be 2-dimension array\n",
    "        y_train and feature_names should be 1-dimension array\n",
    "        \n",
    "        '''\n",
    "        def new_log(n,bottom):\n",
    "            '''\n",
    "            caculate log value with bottom,when n=0,log value=0.\n",
    "        \n",
    "            '''   \n",
    "            import math as m\n",
    "            if n==0:\n",
    "                return 0\n",
    "            else:\n",
    "                return m.log(n,bottom)\n",
    "        \n",
    "        def LabelEncoder(x):\n",
    "            '''\n",
    "            encode array that contains str.\n",
    "        \n",
    "            '''\n",
    "            import numpy as np \n",
    "            n_values=x.shape[0]\n",
    "            new_x=np.full(x.shape[0],np.nan)\n",
    "            catagories=np.unique(x)\n",
    "            new_catagories=np.arange(catagories.shape[0])\n",
    "            for i in range(n_values):\n",
    "                for j in range(catagories.shape[0]):\n",
    "                    if x[i]==catagories[j]:\n",
    "                        new_x[i]=new_catagories[j]\n",
    "            return new_x.astype(int)\n",
    "            \n",
    "        \n",
    "        def labelencoder(x,border):\n",
    "            '''\n",
    "            encode continuous array into 2 catagories:x>border and x<=border.\n",
    "        \n",
    "            '''\n",
    "            n_values=x.shape[0]\n",
    "            new_x=np.full(x.shape[0],np.nan)\n",
    "            for k in range(n_values):\n",
    "                if x[k]>border:\n",
    "                    new_x[k]=1\n",
    "                elif x[k]<=border:\n",
    "                    new_x[k]=0 \n",
    "            return new_x.astype(int)\n",
    "        \n",
    "        def entropy(y):\n",
    "            '''\n",
    "            Caculate the entropy.  \n",
    "            y should be an 1-dimension array as target.\n",
    "            \n",
    "            '''\n",
    "            import numpy as np\n",
    "            catagories,counts=np.unique(y,return_counts=True)\n",
    "            sample_size=y.shape[0]\n",
    "            n_catagories=catagories.shape[0]\n",
    "            entropy=0\n",
    "            for i in range(n_catagories):\n",
    "                entropy-=(counts[i]/sample_size)*new_log(counts[i]/sample_size,2)\n",
    "            return entropy\n",
    "        \n",
    "        def info_gain(x,y):\n",
    "            '''\n",
    "            caculate the information gain.\n",
    "            x should be an 1-dimension array as a column of feature.\n",
    "            y should be an 1-dimension array as target.\n",
    "            \n",
    "            '''\n",
    "            import numpy as np\n",
    "            x_catagories,x_counts=np.unique(x,return_counts=True)\n",
    "            sample_size=x.shape[0]\n",
    "            n_x_catagories=x_catagories.shape[0]\n",
    "            weights=np.full(n_x_catagories,np.nan)\n",
    "            catagory_entropies=np.full(n_x_catagories,np.nan)\n",
    "            for i in range(n_x_catagories):\n",
    "                weights[i]=x_counts[i]/sample_size\n",
    "                catagory_entropies[i]=entropy(y[x==x_catagories[i]]) \n",
    "            info_gain= entropy(y)-np.sum(weights*catagory_entropies) \n",
    "            return info_gain\n",
    "        \n",
    "        def continuous_treatment(x,y,continuous_benchmark=5):\n",
    "            '''\n",
    "            discretize an array that is thought to be continuous according to the numbers of value types it has.\n",
    "            The output is the discretized array and the border that split the continious array calculated by max entropy.\n",
    "            \n",
    "            x,y should be 1-dimension array.\n",
    "            \n",
    "            '''\n",
    "            import numpy as np\n",
    "            n_type_values=np.unique(x).shape[0]\n",
    "            if n_type_values>=continuous_benchmark:\n",
    "                n_values=x.shape[0]\n",
    "                midpoint=np.full(n_values-1,np.nan)\n",
    "                discrete_x=np.full((n_values-1,n_values),np.nan)\n",
    "                info_gains=np.full(n_values-1,np.nan)\n",
    "                value_sort=np.sort(x)\n",
    "                for i in range(n_values-1):\n",
    "                    midpoint[i]=(x[i+1]-x[i])/2+x[i]\n",
    "                    discrete_x[i]=labelencoder(x,midpoint[i])\n",
    "                    info_gains[i]=info_gain(discrete_x[i],y)\n",
    "                final_border=np.random.RandomState(123).choice(midpoint[info_gains==np.max(info_gains)])\n",
    "                return final_border,labelencoder(x,final_border)\n",
    "            else:\n",
    "                return 'Originally discrete, no need to discretize',x\n",
    "        \n",
    "        def best_feature(x_y,feature_names):\n",
    "            '''\n",
    "            Return the feature with max info_gain so that the dataframe can be splited next\n",
    "            x_y should be an 2-dimension array as features and target.\n",
    "        \n",
    "            '''\n",
    "            import numpy as np\n",
    "            x,y=np.hsplit(x_y,[x_y.shape[1]-1])\n",
    "            info_gains=np.full(x.shape[1],np.nan)\n",
    "            for i in range(x.shape[1]):\n",
    "                info_gains[i]=info_gain(x[:,i],y)\n",
    "            best_feature_index=np.random.RandomState(123).choice(np.arange(x.shape[1])[info_gains==np.max(info_gains)])\n",
    "            best_feature=feature_names[best_feature_index]\n",
    "            return best_feature,best_feature_index\n",
    "\n",
    "        def data_split(x_y,best_feature_index,catagory):\n",
    "            '''\n",
    "            split the dataframe according to the best_feature_indx,and the catagory of best_feature\n",
    "            \n",
    "            '''\n",
    "            import numpy as np\n",
    "            sorted_x_y=x_y[x_y[:,best_feature_index].argsort()]\n",
    "            splited_data=sorted_x_y[sorted_x_y[:,best_feature_index]==catagory]\n",
    "            return splited_data\n",
    "            \n",
    "        def create_tree(x_y,feature_names):\n",
    "            '''\n",
    "            create the tree in the form of dictionary\n",
    "\n",
    "            '''\n",
    "            import numpy as np\n",
    "            x,y=np.hsplit(x_y,[x_y.shape[1]-1])\n",
    "            if np.unique(y).shape[0]==1:\n",
    "                return str(int(np.unique(y)))\n",
    "            else:\n",
    "                best_feat,best_feat_index=best_feature(x_y,feature_names)\n",
    "                tree={best_feat:{}}\n",
    "                for catagory in range(np.unique(x[:,best_feat_index]).shape[0]):\n",
    "                    tree[best_feat][catagory]=create_tree(data_split(x_y,best_feat_index,catagory),feature_names)\n",
    "                return tree\n",
    "  \n",
    "#  Encode data and treat continous data\n",
    "        import numpy as np\n",
    "        y_train=LabelEncoder(y_train)\n",
    "        for i in range(x_train.shape[1]):\n",
    "            x_train[:,i]=continuous_treatment(x_train[:,i],y_train)[1]\n",
    "            x_train[:,i]=LabelEncoder(x_train[:,i])\n",
    "        x_y=np.concatenate((x_train,y_train[:,np.newaxis]),axis=1) \n",
    "        tree=create_tree(x_y,feature_names)\n",
    "        self.tree=tree \n",
    "        \n",
    "    def predict(self,x_test):\n",
    "        '''\n",
    "        x_test should be a 2-dimension array\n",
    "\n",
    "        '''\n",
    "        def single_predict(tree,single_x_test):\n",
    "            '''\n",
    "            this function predict a test point, x_test should be a dictionary of a single data point\n",
    "            \n",
    "            '''\n",
    "            first=list(tree.keys())[0]\n",
    "            second=single_x_test[first]\n",
    "            edege=tree[first][second]\n",
    "            if isinstance(edege,str)==True:\n",
    "                predict=edege\n",
    "            else:\n",
    "                predict=single_predict(edege,single_x_test)\n",
    "            return predict\n",
    "        import numpy as np\n",
    "        empty_x_test=np.full(x_test.shape[0],np.nan)\n",
    "        for i,single_x_test in enumerate(x_test):\n",
    "            single_x_test=single_x_test.tolist()\n",
    "            single_x_test={feature_names:single_x_test for feature_names,single_x_test in zip(feature_names,single_x_test)}\n",
    "            empty_x_test[i]=single_predict(self.tree,single_x_test) \n",
    "        return empty_x_test\n",
    "        \n",
    "#test\n",
    "import numpy as np\n",
    "x_train=np.array([[0,2,0,0],[0,2,0,1],[1,2,0,0],[2,1,0,0],[2,0,1,0],[2,0,1,1],[1,0,1,1],[0,1,0,0],[0,0,1,0],[2,1,1,0],[0,1,1,1],\n",
    "            [1,1,0,1],[1,2,1,0],[2,1,0,1]])\n",
    "y_train=np.array([0,0,1,1,1,0,1,0,1,1,1,1,1,0])\n",
    "x_test=np.array([[0,2,0,0],[0,2,0,1],[1,2,0,0],[2,1,0,0],[2,0,1,0],[2,0,1,1]])\n",
    "feature_names=np.array(['age','income','student','credit'])\n",
    "clf=Tree()\n",
    "clf.fit(x_train,y_train,feature_names)\n",
    "clf.tree,clf.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
